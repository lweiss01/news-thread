---
wave: 1
depends_on: []
files_modified:
  - app/build.gradle
  - app/src/main/assets/sentence_model_v1.tflite (new)
  - app/src/main/assets/vocab.txt (new)
autonomous: false
---

# Plan 03-01: TensorFlow Lite Dependencies and Model Setup

## Objective

Set up TensorFlow Lite infrastructure for Phase 3 by adding dependencies, downloading the quantized all-MiniLM-L6-v2 model, and configuring the Android build system.

## Context

Phase 3 builds semantic embedding generation into the app using TensorFlow Lite. This plan establishes the foundation by:
- Adding TF Lite dependencies
- Downloading and bundling the model file
- Configuring build settings to prevent model compression

No code changes yet - this is infrastructure setup only.

## Tasks

### Task 1: Add TensorFlow Lite Dependencies
<task>
<action>
Add the following dependencies to `app/build.gradle` in the `dependencies` block:

```gradle
// TensorFlow Lite
implementation 'org.tensorflow:tensorflow-lite:2.14.0'
implementation 'org.tensorflow:tensorflow-lite-support:0.4.4'
```
</action>
<test>
Sync Gradle and verify dependencies resolve without errors.
</test>
</task>

### Task 2: Configure Build to Prevent Model Compression
<task>
<action>
Add `aaptOptions` to `app/build.gradle` in the `android` block to prevent Android from compressing `.tflite` files:

```gradle
android {
    ...
    aaptOptions {
        noCompress "tflite"
    }
}
```

Why: Android compresses `.tflite` files by default, causing runtime loading failures.
</action>
<test>
Verify `aaptOptions` is present in build.gradle.
</test>
</task>

### Task 3: Download Quantized all-MiniLM-L6-v2 Model
<task>
<action>
User action required: Download the quantized INT8 TFLite model and vocab file:

1. Navigate to HuggingFace: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
2. Look for TFLite quantized version (or use conversion tool)
3. Download `model_quantized.tflite` (~23MB)
4. Download `vocab.txt` (~230KB)

Alternative: Use pre-converted model from TFLite Model Hub or convert using:
```bash
pip install sentence-transformers tensorflow
python -m sentence_transformers.util --convert all-MiniLM-L6-v2 --output model.tflite --quantize
```

Note: This is a one-time setup task. Model files are not in version control due to size.
</action>
<test>
Verify `sentence_model_v1.tflite` and `vocab.txt` exist locally.
</test>
</task>

### Task 4: Add Model Files to Assets
<task>
<action>
Create `app/src/main/assets/` directory if it doesn't exist, then:

1. Rename downloaded model to `sentence_model_v1.tflite`
2. Copy `sentence_model_v1.tflite` to `app/src/main/assets/`
3. Copy `vocab.txt` to `app/src/main/assets/`

Verify files are in the correct location:
- `app/src/main/assets/sentence_model_v1.tflite` (~23MB)
- `app/src/main/assets/vocab.txt` (~230KB)
</action>
<test>
List files in `app/src/main/assets/` and confirm both files exist.
Add `.tflite` files to `.gitignore` to avoid committing large binaries.
</test>
</task>

### Task 5: Verify Build with New Dependencies
<task>
<action>
Build the app to verify dependencies and asset loading work:

```bash
./gradlew assembleDebug
```

Check build output for:
- TF Lite dependencies resolved
- Asset files included in APK
- No compression warnings for `.tflite` files
</action>
<test>
Build succeeds and APK size increases by ~25MB (model + vocab).
</test>
</task>

## Verification Criteria

- [ ] TF Lite dependencies added to build.gradle
- [ ] `aaptOptions { noCompress "tflite" }` configured
- [ ] `sentence_model_v1.tflite` exists in assets/
- [ ] `vocab.txt` exists in assets/
- [ ] App builds successfully
- [ ] APK size increased by ~25MB

## Must-Haves (Goal-Backward Verification)

**Phase 3 Goal**: Generate semantic embeddings on-device using TensorFlow Lite

**This plan must deliver**:
- TF Lite runtime available for embedding generation
- all-MiniLM-L6-v2 model bundled in app
- Model loadable at runtime (not compressed)

## Notes

- Model files are large (~23MB) - consider .gitignore
- User must download model manually (not in version control)
- Quantized INT8 model chosen per user decision in 03-CONTEXT.md
- This plan has NO code changes - pure infrastructure setup
