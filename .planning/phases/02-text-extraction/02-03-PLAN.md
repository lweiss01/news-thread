---
phase: 02-text-extraction
plan: 03
type: execute
wave: 3
depends_on: ["02-01", "02-02"]
files_modified:
  - app/src/main/java/com/newsthread/app/data/repository/UserPreferencesRepository.kt
  - app/src/main/java/com/newsthread/app/data/repository/TextExtractionRepository.kt
  - app/src/main/java/com/newsthread/app/data/local/dao/CachedArticleDao.kt
  - app/src/main/java/com/newsthread/app/di/RepositoryModule.kt
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User preference for article fetching persists across app restarts"
    - "TextExtractionRepository orchestrates fetch -> parse -> save pipeline"
    - "Extraction respects user's WiFi-only preference"
    - "Paywall detection prevents storing empty/stub content"
    - "Extraction falls back gracefully when fetch fails"
  artifacts:
    - path: "app/src/main/java/com/newsthread/app/data/repository/UserPreferencesRepository.kt"
      provides: "DataStore-backed preference storage"
      contains: "articleFetchPreference"
    - path: "app/src/main/java/com/newsthread/app/data/repository/TextExtractionRepository.kt"
      provides: "Extraction orchestration"
      contains: "fun extractAndSave"
    - path: "app/src/main/java/com/newsthread/app/data/local/dao/CachedArticleDao.kt"
      provides: "Query for articles needing extraction"
      contains: "getArticlesNeedingExtraction"
  key_links:
    - from: "TextExtractionRepository"
      to: "ArticleHtmlFetcher"
      via: "HTML fetch step"
      pattern: "articleHtmlFetcher\\.fetch"
    - from: "TextExtractionRepository"
      to: "Readability4JExtended"
      via: "Article parsing"
      pattern: "Readability4JExtended"
    - from: "TextExtractionRepository"
      to: "PaywallDetector"
      via: "Pre-extraction paywall check"
      pattern: "PaywallDetector\\.detectPaywall"
    - from: "TextExtractionRepository"
      to: "CachedArticleDao"
      via: "Save extracted text"
      pattern: "cachedArticleDao\\.updateFullText"
    - from: "UserPreferencesRepository"
      to: "DataStore"
      via: "Preference persistence"
      pattern: "dataStore\\.data"
---

<objective>
Create the core extraction repositories: UserPreferencesRepository for fetch preference persistence, and TextExtractionRepository that orchestrates the full extraction pipeline (fetch HTML -> detect paywall -> parse with Readability4J -> save to Room).

Purpose: This is the heart of Phase 2 - connecting all the infrastructure (OkHttp, Readability4J, PaywallDetector, NetworkMonitor) into a working pipeline that respects user preferences and handles failures gracefully.

Output:
- UserPreferencesRepository.kt with DataStore-backed ALWAYS/WIFI_ONLY/NEVER preference
- TextExtractionRepository.kt that orchestrates extraction with proper error handling
- CachedArticleDao.kt updated with getArticlesNeedingExtraction query
- RepositoryModule.kt updated with UserPreferencesRepository binding
</objective>

<execution_context>
@C:\Users\lweis\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lweis\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-text-extraction/02-RESEARCH.md

# Prior plan context
@.planning/phases/02-text-extraction/02-01-PLAN.md
@.planning/phases/02-text-extraction/02-02-PLAN.md

# Existing files to reference/modify
@app/src/main/java/com/newsthread/app/data/local/dao/CachedArticleDao.kt
@app/src/main/java/com/newsthread/app/di/RepositoryModule.kt
@app/src/main/java/com/newsthread/app/data/repository/QuotaRepository.kt
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create UserPreferencesRepository</name>
  <files>app/src/main/java/com/newsthread/app/data/repository/UserPreferencesRepository.kt</files>
  <action>
Create UserPreferencesRepository that persists the article fetch preference to DataStore.

Key requirements:
- Inject DataStore<Preferences>
- Expose articleFetchPreference as Flow<ArticleFetchPreference>
- Default to WIFI_ONLY per user decision in 02-CONTEXT.md
- Provide setArticleFetchPreference() suspend function
- Use intPreferencesKey for enum ordinal storage

```kotlin
package com.newsthread.app.data.repository

import androidx.datastore.core.DataStore
import androidx.datastore.preferences.core.Preferences
import androidx.datastore.preferences.core.edit
import androidx.datastore.preferences.core.intPreferencesKey
import com.newsthread.app.domain.model.ArticleFetchPreference
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.map
import javax.inject.Inject
import javax.inject.Singleton

@Singleton
class UserPreferencesRepository @Inject constructor(
    private val dataStore: DataStore<Preferences>
) {
    /**
     * User's preference for when to fetch full article text.
     * Defaults to WIFI_ONLY (most conservative for new users).
     */
    val articleFetchPreference: Flow<ArticleFetchPreference> = dataStore.data
        .map { prefs ->
            val ordinal = prefs[ARTICLE_FETCH_PREF_KEY] ?: ArticleFetchPreference.WIFI_ONLY.ordinal
            ArticleFetchPreference.entries[ordinal]
        }

    /**
     * Updates the article fetch preference.
     *
     * @param preference New preference value (ALWAYS, WIFI_ONLY, or NEVER)
     */
    suspend fun setArticleFetchPreference(preference: ArticleFetchPreference) {
        dataStore.edit { prefs ->
            prefs[ARTICLE_FETCH_PREF_KEY] = preference.ordinal
        }
    }

    companion object {
        val ARTICLE_FETCH_PREF_KEY = intPreferencesKey("article_fetch_preference")
    }
}
```
  </action>
  <verify>
Grep for key patterns:
- "val articleFetchPreference: Flow<ArticleFetchPreference>"
- "WIFI_ONLY.ordinal" (default)
- "suspend fun setArticleFetchPreference"
- "dataStore.edit"
  </verify>
  <done>UserPreferencesRepository persists fetch preference to DataStore with WIFI_ONLY default</done>
</task>

<task type="auto">
  <name>Task 2: Update CachedArticleDao with extraction query</name>
  <files>app/src/main/java/com/newsthread/app/data/local/dao/CachedArticleDao.kt</files>
  <action>
Add a query method to find articles that need text extraction (fullText is null, not expired).

Add this method to the existing CachedArticleDao interface:

```kotlin
/**
 * Gets articles that need text extraction (fullText is null and article not expired).
 * Orders by fetchedAt DESC to prioritize recently fetched articles.
 *
 * @param now Current timestamp for expiry check
 * @param limit Maximum number of articles to return (for batch processing)
 * @return List of articles needing extraction
 */
@Query("""
    SELECT * FROM cached_articles
    WHERE fullText IS NULL
    AND expiresAt > :now
    ORDER BY fetchedAt DESC
    LIMIT :limit
""")
suspend fun getArticlesNeedingExtraction(
    now: Long = System.currentTimeMillis(),
    limit: Int = 10
): List<CachedArticleEntity>
```

Place this method after the existing updateFullText method to keep related queries together.
  </action>
  <verify>
Grep CachedArticleDao.kt for:
- "fun getArticlesNeedingExtraction"
- "WHERE fullText IS NULL"
- "LIMIT :limit"
  </verify>
  <done>CachedArticleDao has getArticlesNeedingExtraction query for batch extraction processing</done>
</task>

<task type="auto">
  <name>Task 3: Create TextExtractionRepository</name>
  <files>app/src/main/java/com/newsthread/app/data/repository/TextExtractionRepository.kt</files>
  <action>
Create TextExtractionRepository that orchestrates the full extraction pipeline.

Key requirements:
- Inject ArticleHtmlFetcher, CachedArticleDao, UserPreferencesRepository, NetworkMonitor
- Check user preference and network state before fetching
- Check for paywall before parsing
- Use Readability4JExtended for parsing
- Minimum content length threshold: 100 chars
- Save extracted text to Room via CachedArticleDao.updateFullText
- Return ExtractionResult for type-safe handling

```kotlin
package com.newsthread.app.data.repository

import android.util.Log
import com.newsthread.app.data.local.dao.CachedArticleDao
import com.newsthread.app.data.local.entity.CachedArticleEntity
import com.newsthread.app.data.remote.ArticleHtmlFetcher
import com.newsthread.app.domain.model.ArticleFetchPreference
import com.newsthread.app.domain.model.ExtractionResult
import com.newsthread.app.util.NetworkMonitor
import com.newsthread.app.util.PaywallDetector
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.first
import kotlinx.coroutines.withContext
import net.dankito.readability4j.extended.Readability4JExtended
import javax.inject.Inject
import javax.inject.Singleton

@Singleton
class TextExtractionRepository @Inject constructor(
    private val articleHtmlFetcher: ArticleHtmlFetcher,
    private val cachedArticleDao: CachedArticleDao,
    private val userPreferencesRepository: UserPreferencesRepository,
    private val networkMonitor: NetworkMonitor
) {
    /**
     * Extracts article text and saves it to the database.
     *
     * Flow:
     * 1. Check user preference and network state
     * 2. Fetch HTML via ArticleHtmlFetcher
     * 3. Check for paywall indicators
     * 4. Parse with Readability4JExtended
     * 5. Validate content quality
     * 6. Save to Room
     *
     * @param article Cached article entity to extract text for
     * @return ExtractionResult indicating success or failure type
     */
    suspend fun extractAndSave(article: CachedArticleEntity): ExtractionResult = withContext(Dispatchers.IO) {
        // Step 1: Check user preference
        val preference = userPreferencesRepository.articleFetchPreference.first()

        if (!shouldFetch(preference)) {
            return@withContext ExtractionResult.NotFetched(
                reason = when (preference) {
                    ArticleFetchPreference.NEVER -> "Article fetching disabled in settings"
                    ArticleFetchPreference.WIFI_ONLY -> "On metered network, WiFi-only enabled"
                    ArticleFetchPreference.ALWAYS -> "No network available"
                }
            )
        }

        // Step 2: Fetch HTML
        val html = articleHtmlFetcher.fetch(article.url)
            ?: return@withContext ExtractionResult.NetworkError("Failed to fetch HTML from ${article.url}")

        // Step 3: Check for paywall indicators
        if (PaywallDetector.detectPaywall(html)) {
            Log.w(TAG, "Paywall detected for: ${article.url}")
            return@withContext ExtractionResult.PaywallDetected(
                reason = "Paywall markers detected in HTML"
            )
        }

        // Step 4 & 5: Parse with Readability4J and validate
        try {
            val readability = Readability4JExtended(article.url, html)
            val extracted = readability.parse()

            val textContent = extracted.textContent
            if (textContent.isNullOrBlank() || textContent.length < MIN_CONTENT_LENGTH) {
                Log.w(TAG, "Extracted content too short (${textContent?.length ?: 0} chars) for: ${article.url}")
                return@withContext ExtractionResult.PaywallDetected(
                    reason = "Extracted content too short (${textContent?.length ?: 0} chars), likely paywalled or JS-rendered"
                )
            }

            // Step 6: Save to Room
            cachedArticleDao.updateFullText(article.url, textContent)
            Log.d(TAG, "Successfully extracted ${textContent.length} chars for: ${article.url}")

            ExtractionResult.Success(
                textContent = textContent,
                htmlContent = extracted.contentWithUtf8Encoding,
                title = extracted.title,
                byline = extracted.byline,
                excerpt = extracted.excerpt
            )
        } catch (e: Exception) {
            Log.e(TAG, "Extraction failed for ${article.url}", e)
            ExtractionResult.ExtractionError(e.message ?: "Unknown parsing error")
        }
    }

    /**
     * Extracts text for a single article by URL.
     * Convenience method that looks up the article first.
     *
     * @param url Article URL
     * @return ExtractionResult, or NetworkError if article not found in cache
     */
    suspend fun extractByUrl(url: String): ExtractionResult {
        val article = cachedArticleDao.getByUrl(url)
            ?: return ExtractionResult.NetworkError("Article not found in cache: $url")
        return extractAndSave(article)
    }

    /**
     * Batch extracts articles that need extraction.
     * Useful for background processing.
     *
     * @param limit Maximum articles to process
     * @return Map of URL to ExtractionResult
     */
    suspend fun extractBatch(limit: Int = 10): Map<String, ExtractionResult> {
        val articles = cachedArticleDao.getArticlesNeedingExtraction(limit = limit)
        return articles.associate { article ->
            article.url to extractAndSave(article)
        }
    }

    private fun shouldFetch(preference: ArticleFetchPreference): Boolean {
        return when (preference) {
            ArticleFetchPreference.ALWAYS -> networkMonitor.isNetworkAvailable()
            ArticleFetchPreference.WIFI_ONLY -> networkMonitor.isCurrentlyOnWifi()
            ArticleFetchPreference.NEVER -> false
        }
    }

    companion object {
        private const val TAG = "TextExtractionRepository"
        private const val MIN_CONTENT_LENGTH = 100
    }
}
```
  </action>
  <verify>
Grep for key patterns:
- "suspend fun extractAndSave"
- "articleHtmlFetcher.fetch"
- "PaywallDetector.detectPaywall"
- "Readability4JExtended"
- "cachedArticleDao.updateFullText"
- "MIN_CONTENT_LENGTH = 100"
  </verify>
  <done>TextExtractionRepository orchestrates fetch -> paywall check -> parse -> save with proper error handling</done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Verify UserPreferencesRepository:
   - Grep for "val articleFetchPreference: Flow"
   - Grep for "suspend fun setArticleFetchPreference"
   - Grep for "WIFI_ONLY.ordinal" (default)

2. Verify CachedArticleDao update:
   - Grep for "fun getArticlesNeedingExtraction"
   - Grep for "WHERE fullText IS NULL"

3. Verify TextExtractionRepository:
   - Grep for "suspend fun extractAndSave"
   - Grep for "articleHtmlFetcher.fetch"
   - Grep for "Readability4JExtended"
   - Grep for "PaywallDetector.detectPaywall"
   - Grep for "cachedArticleDao.updateFullText"

4. Verify pipeline connections:
   - TextExtractionRepository imports ArticleHtmlFetcher
   - TextExtractionRepository imports PaywallDetector
   - TextExtractionRepository imports UserPreferencesRepository
   - TextExtractionRepository imports NetworkMonitor
</verification>

<success_criteria>
- UserPreferencesRepository persists ALWAYS/WIFI_ONLY/NEVER to DataStore with WIFI_ONLY default
- CachedArticleDao.getArticlesNeedingExtraction returns articles with null fullText
- TextExtractionRepository.extractAndSave orchestrates full pipeline
- TextExtractionRepository respects user preference and network state
- TextExtractionRepository detects paywalls before and after parsing
- TextExtractionRepository saves extracted text to Room
- All error cases return appropriate ExtractionResult variant
</success_criteria>

<output>
After completion, create `.planning/phases/02-text-extraction/02-03-SUMMARY.md`
</output>
